from tenacity import retry, stop_after_attempt, wait_exponential
from . import BaseTool
from .etl.loader import DataLoader
from .etl.cleaner import DataCleaner
from .etl.analyzer import DataAnalyzer
from .etl.saver import DataSaver
from ..logger import logger


class ETLTool(BaseTool):
    """æ•°æ®ETLä¸æ¢ç´¢åˆ†æå·¥å…·ï½œé›†æˆæ•°æ®åŠ è½½ã€æ¸…æ´—ã€åˆ†æã€å­˜å‚¨å…¨æµç¨‹"""

    name: str = "etl_tool"
    description: str = "æ‰§è¡Œæ•°æ®æ¢ç´¢ã€æ¸…æ´—å’Œè½¬æ¢çš„ETLå·¥å…·"
    parameters: dict = {
        "type": "object",
        "properties": {
            "data_path": {
                "type": "string",
                "description": "æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒcsv/xlsx/parquetï¼‰"
            },
            "clean_config": {
                "type": "object",
                "properties": {
                    "handle_missing": {
                        "type": "string",
                        "enum": ["drop", "fill"],
                        "default": "drop",
                        "description": "ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥ï¼šdrop-åˆ é™¤ç¼ºå¤±å€¼ fill-å¡«å……ç¼ºå¤±å€¼"
                    },
                    "outlier_method": {
                        "type": "string",
                        "enum": ["zscore", "iqr"],
                        "default": "iqr",
                        "description": "å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•ï¼šzscore-Zåˆ†æ•°æ³• iqr-å››åˆ†ä½è·æ³•"
                    }
                }
            },
            "explore_depth": {
                "type": "integer",
                "description": "æ•°æ®æ¢ç´¢æ·±åº¦çº§åˆ«ï¼ˆ1-åŸºç¡€åˆ†æ 2-é«˜çº§åˆ†æ 3-é¢„æµ‹åˆ†æï¼‰",
                "default": 2,
                "minimum": 1,
                "maximum": 3
            }
        },
        "required": ["data_path"]
    }

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        before=lambda _: logger.info("ETLæµç¨‹é‡è¯•ä¸­...")
    )
    async def execute(self, data_path: str, clean_config: dict = None, explore_depth: int = 2) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´ETLæµç¨‹
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒæœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ï¼‰
            clean_config: æ¸…æ´—é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
            explore_depth: åˆ†ææ·±åº¦çº§åˆ«ï¼ˆé»˜è®¤2ï¼‰

        Returns:
            Dict: åŒ…å«åˆ†ææŠ¥å‘Šã€æ¸…æ´—åæ•°æ®è·¯å¾„ã€æ•°æ®å½¢çŠ¶çš„å­—å…¸

        Example:
            await ETLTool().execute(
                data_path="data.csv",
                clean_config={"handle_missing": "fill"},
                explore_depth=3
            )
        """
        try:
            # åˆå§‹åŒ–å·¥å…·ç»„ä»¶
            tools = {
                "loader": DataLoader(),
                "cleaner": DataCleaner(),
                "analyzer": DataAnalyzer(),
                "saver": DataSaver()
            }

            # æ‰§è¡Œæ•°æ®åŠ è½½
            logger.info(f"ğŸ” å¼€å§‹åŠ è½½æ•°æ®ï¼š{data_path}")
            df = await self._safe_execute(tools["loader"], {
                "source_type": self._detect_source_type(data_path),
                "path": data_path
            })

            # æ‰§è¡Œæ•°æ®æ¸…æ´—
            logger.info("ğŸ§¹ æ‰§è¡Œæ•°æ®æ¸…æ´—...")
            cleaned_df = await self._safe_execute(tools["cleaner"], df, clean_config or {})

            # æ‰§è¡Œæ•°æ®åˆ†æ
            logger.info("ğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            report = await self._safe_execute(tools["analyzer"], cleaned_df, {
                "analysis_level": explore_depth
            })

            # ä¿å­˜æ¸…æ´—æ•°æ®
            logger.info("ğŸ’¾ ä¿å­˜å¤„ç†ç»“æœ...")
            output_path = await self._safe_execute(tools["saver"], cleaned_df, {
                "output_format": self._detect_output_format(data_path)
            })

            return {
                "explore_report": report,
                "cleaned_path": output_path,
                "data_shape": cleaned_df.shape
            }

        except Exception as e:
            logger.error(f"ETLæµç¨‹æœ€ç»ˆå¤±è´¥: {str(e)}")
            return {"error": str(e)}
        finally:
            logger.info("âœ… ETLæµç¨‹æ‰§è¡Œå®Œæ¯•")

    def _detect_source_type(self, path: str) -> str:
        """æ™ºèƒ½è¯†åˆ«æ•°æ®æºç±»å‹"""
        if path.startswith(("mysql://", "postgresql://")):
            return "database"
        if path.startswith("http"):
            return "api"
        return "file"

    def _detect_output_format(self, input_path: str) -> str:
        """æ ¹æ®è¾“å…¥è·¯å¾„æ¨æ–­è¾“å‡ºæ ¼å¼"""
        return Path(input_path).suffix.lstrip('.').lower() or 'csv'

    async def _safe_execute(self, tool: BaseTool, *args) -> Any:
        """å¸¦é”™è¯¯å¤„ç†çš„å·¥å…·æ‰§è¡Œæ–¹æ³•"""
        try:
            return await tool.execute(*args)
        except Exception as e:
            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥ [{tool.__class__.__name__}]: {str(e)}")
            raise